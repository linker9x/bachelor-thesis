{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial Book : Forward Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a wrapper method. Forward selection is an iterative method in which we start with having no feature in the model. In each iteration, we keep adding the feature which best improves our model till an addition of a new variable does not improve the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_feature_selection(x_train, x_cv, y_train, y_cv, n):\n",
    "    # start with an empty feature set\n",
    "    feature_set = []\n",
    "    # for the number of features that you want to select (n - based on model performance)\n",
    "    for num_features in range(n):\n",
    "        # entries look like [metric(), feature]\n",
    "        metric_list = []\n",
    "        # choose a model\n",
    "        model = SGDClassifier()\n",
    "        # for all of the features available in the org dataset\n",
    "        for feature in x_train.columns:\n",
    "            # if the feature hasn't already been added to the selected feature set\n",
    "            if feature not in feature_set:\n",
    "                # make a copy of the selected feature set\n",
    "                f_set = feature_set.copy()\n",
    "                # add the new feature to it\n",
    "                f_set.append(feature)\n",
    "                # fit the model using the selected feature set + the new feature\n",
    "                model.fit(x_train[f_set], y_train)\n",
    "                # evaluate the model using the choosen metric and the test data\n",
    "                # add a tuple containing the result and the feature to the metric list\n",
    "                metric_list.append((evaluate_metric(model, x_cv[f_set], y_cv), feature))\n",
    "        # sort the metric list\n",
    "        metric_list.sort(key=lambda x : x[0], reverse = True) \n",
    "        # add the feature with the best metric to the selected feature set\n",
    "        feature_set.append(metric_list[0][1])\n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, jaccard_similarity_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and column names. Then separate the cols containing features and class col."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of dataset:\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "\n",
      "Class col from dataset:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "feat_labels = ['Sepal Length','Sepal Width','Petal Length','Petal Width']\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "print('First 5 rows of dataset:')\n",
    "print(X[0:5])\n",
    "print('\\nClass col from dataset:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the data into a training set and a test set (80/20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we basically do the steps from the commented code above. We start by creating an array to push the features that we select to and choose how many features to select. After that we start selecting the features by creating a model, in this case an SGD Classifier. We then go through all of the features that haven't already been selected and add them individually to the selected feature set. We then fit the model with this extended feature set and evaluate it's performance. The extended feature set with the best performance becomes the new selected feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3333333333333333, 0)]\n",
      "[(0.3333333333333333, 0), (0.3333333333333333, 1)]\n",
      "[(0.3333333333333333, 0), (0.3333333333333333, 1), (0.6666666666666666, 2)]\n",
      "[(0.3333333333333333, 0), (0.3333333333333333, 1), (0.6666666666666666, 2), (0.6666666666666666, 3)]\n",
      "metric_list\n",
      "[(0.6666666666666666, 2), (0.6666666666666666, 3), (0.3333333333333333, 0), (0.3333333333333333, 1)]\n",
      "feature_set\n",
      "[2]\n",
      "[(0.5666666666666667, 0)]\n",
      "[(0.5666666666666667, 0), (0.6666666666666666, 1)]\n",
      "[(0.5666666666666667, 0), (0.6666666666666666, 1), (0.7666666666666667, 3)]\n",
      "metric_list\n",
      "[(0.7666666666666667, 3), (0.6666666666666666, 1), (0.5666666666666667, 0)]\n",
      "feature_set\n",
      "[2, 3]\n",
      "[(0.6333333333333333, 0)]\n",
      "[(0.6333333333333333, 0), (0.36666666666666664, 1)]\n",
      "metric_list\n",
      "[(0.6333333333333333, 0), (0.36666666666666664, 1)]\n",
      "feature_set\n",
      "[2, 3, 0]\n",
      "[(0.6666666666666666, 1)]\n",
      "metric_list\n",
      "[(0.6666666666666666, 1)]\n",
      "feature_set\n",
      "[2, 3, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\linker\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "feature_set = []\n",
    "n = 4\n",
    "for num_features in range(n):\n",
    "    # entries look like [metric(), feature]\n",
    "    metric_list = [] \n",
    "    # using the SGD Classifier, like in the example\n",
    "    model = SGDClassifier(random_state=1000) \n",
    "    # for all of the features available in the iris dataset (petal width, petal length, sepal width, sepal length)\n",
    "    for feature in range(len(feat_labels)):\n",
    "        if feature not in feature_set:\n",
    "            f_set = feature_set.copy()\n",
    "            f_set.append(feature)\n",
    "\n",
    "            X_train_tmp = X_train[:, f_set] #[:, [1, 9]]\n",
    "            model.fit(X_train_tmp, y_train)\n",
    "\n",
    "            X_test_tmp = X_test[:, f_set]\n",
    "            metric_list.append((f1_score(y_test, model.predict(X_test_tmp), average='micro'), feature))\n",
    "            print(metric_list)\n",
    "    # sort the list\n",
    "    metric_list.sort(key=lambda x : x[0], reverse = True)\n",
    "    print('metric_list')\n",
    "    print(metric_list)\n",
    "    # add the feature with the best metric to the selected feature set\n",
    "    feature_set.append(metric_list[0][1])\n",
    "    print('feature_set')\n",
    "    print(feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was giving inconsistent results. It seems to have had something to do with the SGDClassifier. Because random_state defaults to none, the model must have been slightly different each time. I set it to 1000 and it produces the correct/desired result, but there are values for which it produces different results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
